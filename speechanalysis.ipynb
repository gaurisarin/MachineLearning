{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7022289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2646\n",
      "10 most common words:\n",
      " going      114\n",
      "people     107\n",
      "know        72\n",
      "said        58\n",
      "thats       48\n",
      "country     47\n",
      "want        45\n",
      "like        43\n",
      "think       42\n",
      "world       40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mat\n",
    "import seaborn as sb\n",
    "from sklearn import linear_model as lm\n",
    "import math\n",
    "# problem one:\n",
    "#part a\n",
    "#read the file \n",
    "state = pd.read_csv('statements.csv')\n",
    "#convert to lowercase\n",
    "state['text'] = state['text'].str.lower()\n",
    "#remove punctuation \n",
    "state['text'] = state['text'].str.replace('[^\\w\\s]','', regex=True)\n",
    "# remove stop words \n",
    "#open NLTK_English_stopwords.txt file \n",
    "NLTK = open('NLTK_English_stopwords.txt', 'r')\n",
    "#read and split into list of words \n",
    "NLTK = NLTK.read().split('\\n')\n",
    "#remove the list of words from statements.csv\n",
    "state['text'] = state['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (NLTK)]))\n",
    "#consider only words with 4 or more letters\n",
    "state['text'] = state['text'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 3]))\n",
    "#statements file has been cleaned \n",
    "#the number of unique words\n",
    "print(len(set(' '.join(state['text']).split())))\n",
    "#the ten most commonw words \n",
    "print('10 most common words:\\n', pd.Series(' '.join(state['text']).split()).value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb4c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten words closely correlated with Donlad Trump :\n",
      " 0         going\n",
      "8         think\n",
      "2          know\n",
      "3          said\n",
      "11        great\n",
      "38         look\n",
      "12       theyre\n",
      "28       really\n",
      "44    something\n",
      "25        money\n",
      "Name: word, dtype: object\n",
      "Ten words closely correlated with Barack Obama:\n",
      " 17         must\n",
      "43        today\n",
      "36        years\n",
      "91     together\n",
      "59        thank\n",
      "101       stand\n",
      "47         care\n",
      "33         weve\n",
      "106       since\n",
      "111       power\n",
      "Name: word, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>obama_count</th>\n",
       "      <th>obama_sentence_count</th>\n",
       "      <th>trump_count</th>\n",
       "      <th>trump_sentence_count</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going</td>\n",
       "      <td>114</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15</td>\n",
       "      <td>99.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.264308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>107</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.067936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td>72</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.154746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said</td>\n",
       "      <td>58</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.145459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thats</td>\n",
       "      <td>48</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>strength</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>interviewed</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>nine</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>large</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>safety</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count  obama_count  obama_sentence_count  trump_count  \\\n",
       "0          going    114         15.0                    15         99.0   \n",
       "1         people    107         43.0                    44         64.0   \n",
       "2           know     72         16.0                    22         56.0   \n",
       "3           said     58         12.0                    10         46.0   \n",
       "4          thats     48         24.0                    23         24.0   \n",
       "..           ...    ...          ...                   ...          ...   \n",
       "853     strength      2          1.0                     4          1.0   \n",
       "856  interviewed      2          1.0                     1          1.0   \n",
       "857         nine      2          1.0                     1          1.0   \n",
       "859        large      2          1.0                     5          1.0   \n",
       "860       safety      2          1.0                     1          1.0   \n",
       "\n",
       "     trump_sentence_count       phi  \n",
       "0                      81  0.264308  \n",
       "1                      61  0.067936  \n",
       "2                      55  0.154746  \n",
       "3                      43  0.145459  \n",
       "4                      23  0.000000  \n",
       "..                    ...       ...  \n",
       "853                     1  0.000000  \n",
       "856                     1  0.000000  \n",
       "857                     1  0.000000  \n",
       "859                     3  0.000000  \n",
       "860                     1  0.000000  \n",
       "\n",
       "[551 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#problem two\n",
    "#part a\n",
    "def count_words_in_sentences(state, speaker):\n",
    "    #counts number of occurance of word in sentences by president \n",
    "    sentences = state[state['speaker'] == speaker]['text'].str.split().reset_index(drop=True)\n",
    "    count_of_word = pd.Series(np.concatenate(sentences)).value_counts()\n",
    "    return pd.DataFrame({'word': count_of_word.index, f'{speaker}_count': count_of_word.values})\n",
    "def count_sentences_with_word(state, speaker, word):\n",
    "    #number of sentences containing given word \n",
    "    sentences = state[state['speaker'] == speaker]['text']\n",
    "    return pd.DataFrame({f'{speaker}_sentence_count': sentences.str.contains(word).sum()}, index=[word])\n",
    "def calculate_phi_coefficient(trump_count, obama_count, total_trump_sentences, total_obama_sentences):\n",
    "    #calcualte the phi coefficient \n",
    "    a = trump_count\n",
    "    b = obama_count\n",
    "    c = total_trump_sentences - a\n",
    "    d = total_obama_sentences - b\n",
    "    return (a * d - b * c) / np.sqrt((a + b) * (c + d) * (a + c) * (b + d))\n",
    "#number of occurances of each word \n",
    "count_of_word = pd.Series(' '.join(state['text']).split()).value_counts().reset_index()\n",
    "count_of_word.columns = ['word', 'count']\n",
    "#counts the ocuurrances of words spoken by each of the preseidents in the sentences \n",
    "obama_count_of_word = count_words_in_sentences(state, 'obama')\n",
    "trump_count_of_word = count_words_in_sentences(state, 'trump')\n",
    "#counts the number of sentences which contain wach word spoken by each of the presidents \n",
    "obama_sentence_counts = pd.concat([count_sentences_with_word(state, 'obama', word) for word in obama_count_of_word['word']])\n",
    "trump_sentence_counts = pd.concat([count_sentences_with_word(state, 'trump', word) for word in trump_count_of_word['word']])\n",
    "#merges the tables \n",
    "count_of_word = count_of_word.merge(obama_count_of_word, on='word', how='left')\n",
    "count_of_word = count_of_word.merge(obama_sentence_counts, left_on='word', right_index=True)\n",
    "count_of_word = count_of_word.merge(trump_count_of_word, on='word', how='left')\n",
    "count_of_word = count_of_word.merge(trump_sentence_counts, left_on='word', right_index=True)\n",
    "#replaces the NaN values with 0's\n",
    "count_of_word = count_of_word.fillna(0)\n",
    "#phi coeeffficient for each word \n",
    "total_sentences_obama = state[state['speaker'] == 'obama']['text'].count()\n",
    "total_sentences_trump = state[state['speaker'] == 'trump']['text'].count()\n",
    "count_of_word['phi'] = count_of_word.apply(lambda row: calculate_phi_coefficient(row['trump_count'], \n",
    "                                                          row['obama_count'], \n",
    "                                                          total_sentences_trump, total_sentences_obama), axis=1)\n",
    "#ten words correlated with trump\n",
    "trump_words = count_of_word.sort_values('phi', ascending=False)['word'][:10]\n",
    "print('Ten words closely correlated with Donlad Trump :\\n', trump_words)\n",
    "#ten words correlated with obama\n",
    "obama_words = count_of_word.sort_values('phi', ascending=True)['word'][:10]\n",
    "print('Ten words closely correlated with Barack Obama:\\n', obama_words)\n",
    "#sjows the table\n",
    "count_of_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef500b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part b: \n",
    "from math import log\n",
    "import numpy as np\n",
    "def calculate_log_probability(sentence, speaker, probability_before, word_probabality):\n",
    "    \"\"\"\n",
    "    Calculates the log probability of a sentence given a speaker.\n",
    "    Args:\n",
    "        sentence (str): The sentence to calculate the probability of.\n",
    "        speaker (str): The speaker to calculate the probability for.\n",
    "        probability_before (dict): A dictionary of prior probabilities for each speaker.\n",
    "        word_probabality (pd.DataFrame): A DataFrame of word probabilities for each speaker.\n",
    "    Returns:\n",
    "        The log probability of the sentence given the speaker.\n",
    "    \"\"\"\n",
    "    log_probability = np.log(probability_before[speaker])\n",
    "    for word in sentence.split():\n",
    "        if word in word_probabality.columns:\n",
    "            log_probability += np.log(word_probabality.loc[speaker, word])\n",
    "    return log_probability\n",
    "def predict_the_speaker(sentence, probability_before, word_probabality):\n",
    "    \"\"\"\n",
    "    Predicts the speaker of a sentence given prior and word probabilities.\n",
    "    Args:\n",
    "        sentence (str): The sentence to predict the speaker for.\n",
    "        probability_before (dict): A dictionary of prior probabilities for each speaker.\n",
    "        word_probabality (pd.DataFrame): A DataFrame of word probabilities for each speaker.\n",
    "    Returns:\n",
    "        The predicted speaker. Returns '1' if the sentence is more likely to be spoken by Trump, '0' otherwise.\n",
    "    \"\"\"\n",
    "    log_probability_trump = calculate_log_probability(sentence, 'trump', probability_before, word_probabality)\n",
    "    log_probability_obama = calculate_log_probability(sentence, 'obama', probability_before, word_probabality)\n",
    "    if log_probability_trump > log_probability_obama:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "def stats_of_classifier(state, probability_before, word_probabality):\n",
    "    \"\"\"\n",
    "    Calculates the stats of the classifier.\n",
    "    Args:\n",
    "        state (pd.DataFrame): A DataFrame of actual speakers and predicted speakers.\n",
    "        probability_before (dict): A dictionary of prior probabilities for each speaker.\n",
    "        word_probabality (pd.DataFrame): A DataFrame of word probabilities for each speaker.\n",
    "    Returns:\n",
    "        A tuple containing the accuracy, sensitivity, specificity, precision, and F1 score.\n",
    "    \"\"\"\n",
    "    tp = len(state[(state['speaker'] == 'trump') & (state['prediction'] == '1')])\n",
    "    tn = len(state[(state['speaker'] == 'obama') & (state['prediction'] == '0')])\n",
    "    fp = len(state[(state['speaker'] == 'obama') & (state['prediction'] == '1')])\n",
    "    fn = len(state[(state['speaker'] == 'trump') & (state['prediction'] == '0')])\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-10)\n",
    "    sensitivity = tp / (tp + fn + 1e-10)\n",
    "    specificity = tn / (tn + fp + 1e-10)\n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "    f1_score = 2 * (precision * sensitivity) / (precision + sensitivity + 1e-10)\n",
    "    return accuracy, sensitivity, specificity, precision, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a352c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               1000    100000          10th         12000         15000  \\\n",
      "obama  2.719608e-04  0.000272  5.439217e-04  1.000000e-10  1.000000e-10   \n",
      "trump  1.000000e-10  0.000296  1.000000e-10  2.961208e-04  2.961208e-04   \n",
      "\n",
      "              1890s          1967          1991          1993         20000  \\\n",
      "obama  2.719608e-04  2.719608e-04  1.000000e-10  1.000000e-10  1.000000e-10   \n",
      "trump  1.000000e-10  1.000000e-10  2.961208e-04  2.961208e-04  8.883625e-04   \n",
      "\n",
      "       ...     years         yemen     yesterday      york          youd  \\\n",
      "obama  ...  0.004351  2.719608e-04  1.000000e-10  0.000272  1.000000e-10   \n",
      "trump  ...  0.000888  1.000000e-10  2.961208e-04  0.000888  5.922416e-04   \n",
      "\n",
      "          youll     young     youre     youve        zeejah  \n",
      "obama  0.000272  0.000816  0.001360  0.001632  2.719608e-04  \n",
      "trump  0.001481  0.000592  0.001184  0.001777  1.000000e-10  \n",
      "\n",
      "[2 rows x 2646 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate probability of each speaker in the 'state' dataframe\n",
    "probability_before = state.groupby('speaker').size().div(len(state))\n",
    "# Split text by spaces and get unique words\n",
    "unique_word = np.unique(state['text'].str.cat(sep=' ').split())\n",
    "# Create an empty dataframe with the index as speaker names and columns as unique_word\n",
    "word_dataframe = pd.DataFrame(index=['obama', 'trump'], columns=unique_word)\n",
    "# Loop over the speakers in the word_dataframe dataframe\n",
    "for speaker in word_dataframe.index:\n",
    "    # Select only the rows in 'state' dataframe for the current speaker\n",
    "    sentences = state[state['speaker']==speaker]['text']\n",
    "    # Count the number of words for the current speaker\n",
    "    number_words = len(' '.join(sentences).split())\n",
    "    # Count the amount of each word for the current speaker and store in a series\n",
    "    word_frequency = pd.Series(' '.join(sentences).split()).value_counts()\n",
    "    # Calculate the probability of each word for the current speaker and store in the word_dataframe dataframe\n",
    "    word_dataframe.loc[speaker, word_frequency.index] = word_frequency.div(number_words)\n",
    "# Fill any NaN values in the dataframe with a very small number\n",
    "word_dataframe.fillna(1e-10, inplace=True)\n",
    "# Print the resulting dataframe\n",
    "print(word_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccabfb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992\n",
      "Sensitivity: 0.996\n",
      "Specificity: 0.988\n",
      "Precision: 0.9880952380952381\n",
      "F1 score: 0.9920318725099602\n",
      "false positives: 6\n",
      "false negatives: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>log_probability_trump</th>\n",
       "      <th>log_probability_obama</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>obama</td>\n",
       "      <td>recession marvins competitors closed dozens pl...</td>\n",
       "      <td>-122.522934</td>\n",
       "      <td>-63.193913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>obama</td>\n",
       "      <td>rise fall journey nation people</td>\n",
       "      <td>-49.756502</td>\n",
       "      <td>-35.496303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>obama</td>\n",
       "      <td>differences differences personal</td>\n",
       "      <td>-54.176445</td>\n",
       "      <td>-23.936410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>obama</td>\n",
       "      <td>thats weve excluded lobbyists policymaking job...</td>\n",
       "      <td>-163.564001</td>\n",
       "      <td>-73.749987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>obama</td>\n",
       "      <td>recognize many still strong desire focus past</td>\n",
       "      <td>-97.912963</td>\n",
       "      <td>-47.613751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>trump</td>\n",
       "      <td>would like observe moment silence victims attack</td>\n",
       "      <td>-48.197467</td>\n",
       "      <td>-96.541684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>trump</td>\n",
       "      <td>dont give answer going write incredibly negati...</td>\n",
       "      <td>-47.154117</td>\n",
       "      <td>-95.807715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>trump</td>\n",
       "      <td>said possibly join team said</td>\n",
       "      <td>-32.966432</td>\n",
       "      <td>-81.220592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>trump</td>\n",
       "      <td>wanted really really quickly pertain whats goi...</td>\n",
       "      <td>-47.724376</td>\n",
       "      <td>-87.920635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>trump</td>\n",
       "      <td>going election opinion thats based competence</td>\n",
       "      <td>-40.569819</td>\n",
       "      <td>-88.514153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id speaker                                               text  \\\n",
       "0      0   obama  recession marvins competitors closed dozens pl...   \n",
       "1      1   obama                    rise fall journey nation people   \n",
       "2      2   obama                   differences differences personal   \n",
       "3      3   obama  thats weve excluded lobbyists policymaking job...   \n",
       "4      4   obama      recognize many still strong desire focus past   \n",
       "..   ...     ...                                                ...   \n",
       "995  995   trump   would like observe moment silence victims attack   \n",
       "996  996   trump  dont give answer going write incredibly negati...   \n",
       "997  997   trump                       said possibly join team said   \n",
       "998  998   trump  wanted really really quickly pertain whats goi...   \n",
       "999  999   trump      going election opinion thats based competence   \n",
       "\n",
       "     log_probability_trump  log_probability_obama prediction  \n",
       "0              -122.522934             -63.193913          0  \n",
       "1               -49.756502             -35.496303          0  \n",
       "2               -54.176445             -23.936410          0  \n",
       "3              -163.564001             -73.749987          0  \n",
       "4               -97.912963             -47.613751          0  \n",
       "..                     ...                    ...        ...  \n",
       "995             -48.197467             -96.541684          1  \n",
       "996             -47.154117             -95.807715          1  \n",
       "997             -32.966432             -81.220592          1  \n",
       "998             -47.724376             -87.920635          1  \n",
       "999             -40.569819             -88.514153          1  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that calculates the log probability of a sentence given a speaker, word probabilities, and prior probabilities\n",
    "def log_probability(sentence, speaker, word_dataframe, probability_before):  \n",
    "    # Calculate the log of the prior probability for the given speaker\n",
    "    log_probability = log(probability_before[speaker])\n",
    "    # Loop through each word in the sentence and calculate the log probability of each word given the speaker\n",
    "    for word in sentence.split():\n",
    "        if word in word_dataframe.columns:\n",
    "            log_probability += log(word_dataframe.at[speaker, word])\n",
    "    # Return the total log probability of the sentence given the speaker\n",
    "    return log_probability\n",
    "# Apply the 'log_probability' function to each row of the 'state' dataframe for each speaker, and store the results in new columns\n",
    "state['log_probability_trump'] = state['text'].apply(lambda x: log_probability(x, 'trump', word_dataframe, probability_before))\n",
    "state['log_probability_obama'] = state['text'].apply(lambda x: log_probability(x, 'obama', word_dataframe, probability_before))\n",
    "# Create a new column in the 'state' dataframe that predicts the speaker based on the higher log probability\n",
    "state['prediction'] = np.where(state['log_probability_trump'] > state['log_probability_obama'], '1', '0')\n",
    "# Calculate the true positive (TP), true negative (TN), false positive (FP), and false negative (FN) rates\n",
    "TP = np.sum((state['prediction'] == '1') & (state['speaker'] == 'trump'))\n",
    "TN = np.sum((state['prediction'] == '0') & (state['speaker'] == 'obama'))\n",
    "FP = np.sum((state['prediction'] == '1') & (state['speaker'] == 'obama'))\n",
    "FN = np.sum((state['prediction'] == '0') & (state['speaker'] == 'trump'))\n",
    "# Calculate the accuracy, sensitivity, specificity, precision, and F1 score\n",
    "accuracy = (TP + TN) / len(state)\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "f1 = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "# Print the results\n",
    "print('Accuracy:', accuracy)\n",
    "print('Sensitivity:', sensitivity)\n",
    "print('Specificity:', specificity)\n",
    "print('Precision:', precision)\n",
    "print('F1 score:', f1)\n",
    "# Find the number of false positives (predicted as Trump but actually Obama)\n",
    "false_pos = state[(state['prediction'] == '1') & (state['speaker'] == 'obama')]\n",
    "print('false positives:', len(false_pos))\n",
    "# Find the number of false negatives (predicted as Obama but actually Trump)\n",
    "false_neg = state[(state['prediction'] == '0') & (state['speaker'] == 'trump')]\n",
    "print('false negatives:', len(false_neg))\n",
    "# Display the entire 'state' dataframe with the new columns\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f6d58f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calcualtes score difference between log probabality of Trump and Obama\n",
    "state['score_diff'] = state['log_probability_trump'] - state['log_probability_obama']\n",
    "# creates a scatter plot of each score difference \n",
    "mat.scatter(state['id'], state['score_diff'])\n",
    "mat.xlabel('Sentence')\n",
    "mat.ylabel('Score difference')\n",
    "# displays the plot \n",
    "mat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e9836a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part c:\n",
    "def words_lists(words, unique_word, amount_used=False):\n",
    "    # sort the word list and remove duplicates\n",
    "    unique_word = sorted(list(set(unique_word)))\n",
    "    if amount_used:\n",
    "        # if amount_used is True, count the amount of each word in the input list\n",
    "        count = Counter(words)\n",
    "        # return a list of frequency counts for each word in the word list\n",
    "        return [count[w] for w in unique_word]\n",
    "    else:\n",
    "        # if amount_used is False, return a list of 1s and 0s indicating whether each word in the word list is present in the input list\n",
    "        return [int(w in words) for w in unique_word]\n",
    "def the_distance(sena, senb):\n",
    "    # Convert the sentences to vectors using the  function\n",
    "    vectora = words_lists(sena, topmost_word['word'])\n",
    "    vectorb = words_lists(senb, topmost_word['word'])\n",
    "    # Calculate the distance between the two vectors\n",
    "    dist = np.linalg.norm(np.array(vectora) - np.array(vectorb))\n",
    "    return dist\n",
    "def knn(sen, k, train_set):\n",
    "    # Calculate the distance between the input sentence and all sentences in the training set\n",
    "    train_set['distance'] = train_set['text'].apply(lambda x: the_distance(sen, x))\n",
    "    # Sort the training set by distance and take the top k nearest neighbors\n",
    "    sorting = train_set.sort_values(by='distance', ascending=True)\n",
    "    knn_value = sorting.head(k)\n",
    "    # Calculate the probabilities of the sentence being spoken by Trump and Obama based on the k nearest neighbors\n",
    "    probability_trump = len(knn_value[knn_value['speaker'] == 'trump']) / k\n",
    "    probability_obama = len(knn_value[knn_value['speaker'] == 'obama']) / k\n",
    "    # If the probability of Trump is higher, return 1. Otherwise, return 0.\n",
    "    if probability_trump > probability_obama:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "def validation(n, k):\n",
    "    # Divide the data into n folds for cross-validation\n",
    "    n_fold = int(len(state2) / n)\n",
    "    metric_knn = pd.DataFrame(columns=['accuracy', 'sensitivity', 'specificity', 'precision', 'f1'])\n",
    "\n",
    "    for i in range(n):\n",
    "        # Take one fold as the test set and the rest as the training set\n",
    "        train_set = pd.concat([state2.iloc[:i * n_fold], state2.iloc[(i + 1) * n_fold:]]).reset_index(drop=True)\n",
    "        state_test = state2.iloc[i * n_fold:(i + 1) * n_fold].reset_index(drop=True)\n",
    "        # Apply the knn function to each sentence in the test set to get a prediction\n",
    "        state_test['prediction'] = state_test['text'].apply(lambda x: knn(x, k, train_set))\n",
    "        # Calculate various metrics to evaluate the performance of the classifier\n",
    "        accuracy, sensitivity, specificity, precision, f1 = stats_of_classifier(state_test, probability_before, word_probabality)\n",
    "        # Store the metrics in a dataframe\n",
    "        metric_knn.loc[i] = [accuracy, sensitivity, specificity, precision, f1]\n",
    "    # Calculate the mean of the metrics across all folds and add to the dataframe\n",
    "    metric_knn.loc['mean'] = metric_knn.mean()\n",
    "    return metric_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72941c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word  count  obama_count  obama_sentence_count  trump_count  \\\n",
      "0        going    114         15.0                    15         99.0   \n",
      "1       people    107         43.0                    44         64.0   \n",
      "2         know     72         16.0                    22         56.0   \n",
      "3         said     58         12.0                    10         46.0   \n",
      "4        thats     48         24.0                    23         24.0   \n",
      "..         ...    ...          ...                   ...          ...   \n",
      "546  supported      2          1.0                     1          1.0   \n",
      "547   everyday      2          1.0                     1          1.0   \n",
      "548       sent      2          1.0                     3          1.0   \n",
      "549     insist      2          1.0                     2          1.0   \n",
      "550     safety      2          1.0                     1          1.0   \n",
      "\n",
      "     trump_sentence_count       phi  \n",
      "0                      81  0.264308  \n",
      "1                      61  0.067936  \n",
      "2                      55  0.154746  \n",
      "3                      43  0.145459  \n",
      "4                      23  0.000000  \n",
      "..                    ...       ...  \n",
      "546                     1  0.000000  \n",
      "547                     1  0.000000  \n",
      "548                     5  0.000000  \n",
      "549                     1  0.000000  \n",
      "550                     1  0.000000  \n",
      "\n",
      "[551 rows x 7 columns]\n",
      "      id speaker                                               text  \\\n",
      "0    192   obama                    quite year politics also movies   \n",
      "1    506   trump  going make america great folks telling folks g...   \n",
      "2    488   obama  theyre generation innovators theyve changed am...   \n",
      "3     27   obama  given history course guarantees iranian regime...   \n",
      "4    181   obama  full dancing clapping screaming shouting seem ...   \n",
      "..   ...     ...                                                ...   \n",
      "995  874   trump                                        turned game   \n",
      "996  557   trump                  thing bernie sanders common trade   \n",
      "997  642   trump  president adopt strategy focuses three things ...   \n",
      "998  317   obama               want american people know work begun   \n",
      "999  259   obama                      hopes future dreams fulfilled   \n",
      "\n",
      "     log_probability_trump  log_probability_obama prediction  score_diff  \\\n",
      "0               -67.941024             -36.874875          0  -31.066149   \n",
      "1               -59.187572             -83.100774          1   23.913201   \n",
      "2              -139.573069             -67.066475          0  -72.506594   \n",
      "3              -140.347530             -64.605825          0  -75.741704   \n",
      "4              -169.998847             -64.985673          0 -105.013174   \n",
      "..                     ...                    ...        ...         ...   \n",
      "995             -16.249486             -31.235703          1   14.986217   \n",
      "996             -34.967723             -69.071821          1   34.104098   \n",
      "997             -58.131011             -88.431461          1   30.300450   \n",
      "998             -49.173762             -34.561955          0  -14.611807   \n",
      "999             -92.796551             -30.893500          0  -61.903051   \n",
      "\n",
      "                                                vector  \n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "..                                                 ...  \n",
      "995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word_probabality' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hr/rr1h0_1n68lfjhtzkjr4gjm80000gn/T/ipykernel_3778/1596781951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# perform 10-fold cross-validation on 'state2' with a value of k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmetric_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# append the mean accuracy score for this value of k to the 'list_accuracy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlist_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hr/rr1h0_1n68lfjhtzkjr4gjm80000gn/T/ipykernel_3778/481849433.py\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(n, k)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstate_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Calculate various metrics to evaluate the performance of the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_of_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_probabality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Store the metrics in a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mmetric_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_probabality' is not defined"
     ]
    }
   ],
   "source": [
    "# create a copy of the original 'state' dataframe\n",
    "state2 = state.copy()\n",
    "# remove the 'prediction' column from the copied dataframe\n",
    "state2.drop(columns=['prediction'])     \n",
    "# create a list of the top 1000 words from the 'count_of_word' dataframe, \n",
    "#sorted by the absolute value of their 'phi' column\n",
    "set_of_words= list(count_of_word['phi'].abs().sort_values(ascending=False).head(1000).index)\n",
    "# create a new dataframe containing the top 1000 words from 'count_of_word', sorted by their frequency count\n",
    "topmost_word = count_of_word.loc[count_of_word.index.isin(set_of_words)].sort_values(by='count', ascending=False).reset_index(drop=True) \n",
    "print(topmost_word)\n",
    "# shuffle the rows in the 'state2' dataframe\n",
    "state2 = state2.sample(frac=1).reset_index(drop=True)  \n",
    "# create a new column in the 'state2' dataframe called 'vector', \n",
    "#which contains the word vectors of each sentence in 'state2'\n",
    "state2['vector'] = state2['text'].apply(lambda x: words_lists(x, topmost_word['word']))    \n",
    "print(state2)\n",
    "# create an empty list to store the accuracy scores for each value of k\n",
    "list_accuracy = [] \n",
    "# iterate over values of k from 1 to 31 in steps of 2\n",
    "for k in range(1, 32, 2):\n",
    "    # perform 10-fold cross-validation on 'state2' with a value of k\n",
    "    metric_knn = validation(10, k) \n",
    "    # append the mean accuracy score for this value of k to the 'list_accuracy'\n",
    "    list_accuracy.append(metric_knn['accuracy']['mean'])\n",
    "    # print the results of cross-validation for this value of k\n",
    "    print(metric_knn) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e811185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line creates a line plot of the values in the list 'list_accuracy'\n",
    "# against the values generated by the range function (1, 3, ..., 31).\n",
    "# The x-axis will be labeled with these values, and the y-axis will\n",
    "# be labeled with the values in 'list_accuracy'.\n",
    "mat.plot(range(1, 32, 2), list_accuracy)\n",
    "# This line sets the label for the x-axis of the plot.\n",
    "mat.xlabel('k')\n",
    "# This line sets the label for the y-axis of the plot.\n",
    "mat.ylabel('Accuracy')\n",
    "# This line displays the plot.\n",
    "mat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5076a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
